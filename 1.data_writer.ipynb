{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f9ae95-3efd-4e3f-b055-f3b2391e449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
    "    AutoModelForQuestionAnswering, Trainer, TrainingArguments, HfArgumentParser\n",
    "from run.helpers import prepare_dataset_nli, prepare_train_dataset_qa, \\\n",
    "    prepare_validation_dataset_qa, QuestionAnsweringTrainer, compute_accuracy\n",
    "import os\n",
    "import json\n",
    "\n",
    "NUM_PREPROCESSING_WORKERS = 2\n",
    "\n",
    "dataset_id = ('snli',)\n",
    "\n",
    "dataset = datasets.load_dataset(*dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4c2511-28a6-4fd1-9f3c-86f387abb1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions\n",
    "def remove_premise(data):\n",
    "    new_data = []\n",
    "    for ex in data:\n",
    "        #premise = ex['premise']\n",
    "        premise = ''\n",
    "        hypothesis = ex['hypothesis']\n",
    "        label = ex['label']\n",
    "        if label == -1: continue\n",
    "        tem_dict = {'premise': premise, 'hypothesis': hypothesis, 'label': label}\n",
    "        new_data.append(tem_dict)\n",
    "    return new_data\n",
    "\n",
    "\n",
    "def write_json(data, fn):\n",
    "    with open(fn, 'w') as json_file:\n",
    "        for d in data:\n",
    "            if d['label'] > -1:\n",
    "                json.dump(d, json_file)\n",
    "                json_file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf2b1fa-a48f-43de-bfbf-f9be42cb02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "val_data = dataset['validation'] \n",
    "test_data = dataset['test'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e325f9-8e5d-4e83-9537-23c6cedc23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rm = remove_premise(train_data)\n",
    "val_rm = remove_premise(val_data)\n",
    "test_rm = remove_premise(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a79c81a-ed29-4fd7-8f2f-079f8ec0e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data'): os.mkdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d034e39f-c747-4c9f-8937-00fd754704e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(train_rm, 'data/train_rm.json')\n",
    "write_json(val_rm, 'data/val_rm.json')\n",
    "write_json(test_rm, 'data/test_rm.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "097a8fa2-c79b-4a99-a783-927041a40571",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(train_data, 'data/train_data.json')\n",
    "write_json(val_data, 'data/val_data.json')\n",
    "write_json(test_data, 'data/test_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf938297-6755-4b0a-8759-f4cc3844c445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcb65f-5095-447e-b3cb-f1e75e076a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834480cd-1800-4a6f-9c2f-ce19d8922fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
